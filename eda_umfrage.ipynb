{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "638931a4",
   "metadata": {},
   "source": [
    "# Survey Exploratory Data Analysis Report\n",
    "\n",
    "This notebook performs an automated EDA on the `umfrage.xlsx` file containing survey responses from dental practice staff. All outputs are generated automatically via GitHub Actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daccc2c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:42.686184Z",
     "iopub.status.busy": "2025-10-30T11:45:42.685988Z",
     "iopub.status.idle": "2025-10-30T11:45:43.269613Z",
     "shell.execute_reply": "2025-10-30T11:45:43.268487Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Configure matplotlib based on environment\n",
    "# In GitHub Actions, MPLBACKEND is set to 'Agg' via environment variable\n",
    "# Locally, use the default interactive backend\n",
    "if os.environ.get('MPLBACKEND') == 'Agg':\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    plt.ioff()\n",
    "\n",
    "# Ensure plots are saved with high DPI for better quality\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14416d48",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect Survey Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df466a52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:43.271754Z",
     "iopub.status.busy": "2025-10-30T11:45:43.271492Z",
     "iopub.status.idle": "2025-10-30T11:45:43.380120Z",
     "shell.execute_reply": "2025-10-30T11:45:43.379177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey Dataset Shape: 26 responses and 32 columns\n",
      "\n",
      "First 2 responses (basic info only):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Startzeit</th>\n",
       "      <th>Fertigstellungszeit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-10-23 14:33:46</td>\n",
       "      <td>2025-10-23 14:47:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-10-23 15:09:21</td>\n",
       "      <td>2025-10-23 15:16:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Name           Startzeit Fertigstellungszeit\n",
       "0   1   NaN 2025-10-23 14:33:46 2025-10-23 14:47:53\n",
       "1   2   NaN 2025-10-23 15:09:21 2025-10-23 15:16:48"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the survey data\n",
    "df = pd.read_excel('umfrage.xlsx')\n",
    "\n",
    "print(f\"Survey Dataset Shape: {df.shape[0]} responses and {df.shape[1]} columns\")\n",
    "print(\"\\nFirst 2 responses (basic info only):\")\n",
    "display(df[['ID', 'Name', 'Startzeit', 'Fertigstellungszeit']].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d426b9d",
   "metadata": {},
   "source": [
    "## 2. Data Quality Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf37c04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:43.382212Z",
     "iopub.status.busy": "2025-10-30T11:45:43.382011Z",
     "iopub.status.idle": "2025-10-30T11:45:43.386876Z",
     "shell.execute_reply": "2025-10-30T11:45:43.385989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types Overview:\n",
      "Total columns: 32\n",
      "Text columns: 27\n",
      "Numeric columns: 3\n",
      "DateTime columns: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Types Overview:\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"Text columns: {df.select_dtypes(include=['object']).shape[1]}\")\n",
    "print(f\"Numeric columns: {df.select_dtypes(include=['int64', 'float64']).shape[1]}\")\n",
    "print(f\"DateTime columns: {df.select_dtypes(include=['datetime64']).shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68b81815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:43.388767Z",
     "iopub.status.busy": "2025-10-30T11:45:43.388572Z",
     "iopub.status.idle": "2025-10-30T11:45:43.393906Z",
     "shell.execute_reply": "2025-10-30T11:45:43.392954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in key columns:\n",
      "ID: 0 (0.0%)\n",
      "Name: 26 (100.0%)\n",
      "Startzeit: 0 (0.0%)\n",
      "Fertigstellungszeit: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in key columns\n",
    "key_columns = ['ID', 'Name', 'Startzeit', 'Fertigstellungszeit']\n",
    "missing_key = df[key_columns].isnull().sum()\n",
    "print(\"Missing values in key columns:\")\n",
    "for col, missing in missing_key.items():\n",
    "    print(f\"{col}: {missing} ({missing/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83604c1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:43.395660Z",
     "iopub.status.busy": "2025-10-30T11:45:43.395478Z",
     "iopub.status.idle": "2025-10-30T11:45:43.399847Z",
     "shell.execute_reply": "2025-10-30T11:45:43.399021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Survey Completion Rate: 92.8%\n",
      "Total missing values: 60 out of 832 possible answers\n"
     ]
    }
   ],
   "source": [
    "# Overall completion rate\n",
    "total_possible_answers = df.shape[0] * df.shape[1]\n",
    "total_missing = df.isnull().sum().sum()\n",
    "completion_rate = (total_possible_answers - total_missing) / total_possible_answers * 100\n",
    "print(f\"Overall Survey Completion Rate: {completion_rate:.1f}%\")\n",
    "print(f\"Total missing values: {total_missing} out of {total_possible_answers} possible answers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27ec920",
   "metadata": {},
   "source": [
    "## 3. Response Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ce728",
   "metadata": {},
   "source": [
    "### Survey Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fdb5f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:43.402013Z",
     "iopub.status.busy": "2025-10-30T11:45:43.401820Z",
     "iopub.status.idle": "2025-10-30T11:45:43.409476Z",
     "shell.execute_reply": "2025-10-30T11:45:43.408664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey Completion Statistics:\n",
      "Average completion time: 58.2 minutes\n",
      "Median completion time: 29.2 minutes\n",
      "Fastest completion: 7.5 minutes\n",
      "Slowest completion: 387.2 minutes\n"
     ]
    }
   ],
   "source": [
    "# Convert time columns to datetime if they're not already\n",
    "if 'Startzeit' in df.columns:\n",
    "    df['Startzeit'] = pd.to_datetime(df['Startzeit'], errors='coerce')\n",
    "if 'Fertigstellungszeit' in df.columns:\n",
    "    df['Fertigstellungszeit'] = pd.to_datetime(df['Fertigstellungszeit'], errors='coerce')\n",
    "\n",
    "# Calculate completion time\n",
    "if 'Startzeit' in df.columns and 'Fertigstellungszeit' in df.columns:\n",
    "    df['completion_duration'] = (df['Fertigstellungszeit'] - df['Startzeit']).dt.total_seconds() / 60\n",
    "    \n",
    "    print(\"Survey Completion Statistics:\")\n",
    "    print(f\"Average completion time: {df['completion_duration'].mean():.1f} minutes\")\n",
    "    print(f\"Median completion time: {df['completion_duration'].median():.1f} minutes\")\n",
    "    print(f\"Fastest completion: {df['completion_duration'].min():.1f} minutes\")\n",
    "    print(f\"Slowest completion: {df['completion_duration'].max():.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cafe641",
   "metadata": {},
   "source": [
    "### Professional Background Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "365ba5c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:43.411500Z",
     "iopub.status.busy": "2025-10-30T11:45:43.411316Z",
     "iopub.status.idle": "2025-10-30T11:45:43.416320Z",
     "shell.execute_reply": "2025-10-30T11:45:43.415416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roles mentioned in responses:\n",
      "Response 1: Zahnaerztin mit diverse adm Aufgaben\n",
      "Response 2: Oralchirurgin / Zahnärztin; Praxisinhaberin\n",
      "Response 3: Zahnärztin\n",
      "Response 4: Dentalsekretärin, Administration und Dentalassistentin, wo es mich gerade braucht\n",
      "Response 5: Ich arbeite als Praxiskoordinatorin und bin für die Terminvergabe, Kreditoren, Debitoren und Persona...\n",
      "Response 6: Praxisinhaberin, Zahnärztin\n",
      "Response 7: Praxisinhaberin, Patientenbehandlung, Planung, Personalmanagment, alle administrativen Aufgaben des ...\n",
      "Response 8: Praxisadministratorin.\n",
      "Administrative Arbeiten inkl. dem Tagesablauf  managen\n",
      "Response 9: Zahnarzt , Einzelpraxis\n",
      "Response 10: Praxismanagerin\n",
      "Telefonate, Terminvergabe, Korrespondenz mit Versicherungen etc., Rechnungs- und Mah...\n",
      "Response 11: Administration, Buchhaltung, Personalwesen\n",
      "Response 12: Empfang und Labor\n",
      "Response 13: Praxisinhaber\n",
      "Response 14: Zahnarzt und Eigentümer der Praxus\n",
      "Zahnmedizin\n",
      "Response 15: Zahnarzt in eigener Praxis tätig. \n",
      "Behandlung von Patienten, Personalmanagement, Umsetzung von Vorga...\n",
      "Response 16: Zahnarzt und Inhaber\n",
      "Response 17: Chef, alles\n",
      "Response 18: Zahnarzt, Personalchef, Geschäftsführer und Inhaber\n",
      "Response 19: Praxisinhaber\n",
      "Response 20: Besitzer und Chef\n",
      "Response 21: Praxismanagerin\n",
      "Response 22: Ich bin leitende Dentalassistentin \n",
      "Response 23: Zahnarzt , Einzelpaxis, Chef.\n",
      "Zuständig für fast alles - was nicht abdelegiert ist. \n",
      "Response 24: Zahnarzt/Geschäftsführer\n",
      "Response 25: Praxisinhaber und in allen Bereichen der Zahnmedizin (ausser Kieferorthopädie) tätig. \n",
      "Response 26: Geschäftsleitung, Finanzen & Controlling, HR & Organisationsentwicklung, IT & Technik, Qualitätsmana...\n"
     ]
    }
   ],
   "source": [
    "# Find role/position column (it has a long German name)\n",
    "role_col = None\n",
    "for col in df.columns:\n",
    "    if 'Rolle in der Praxis' in col:\n",
    "        role_col = col\n",
    "        break\n",
    "\n",
    "if role_col:\n",
    "    print(\"Roles mentioned in responses:\")\n",
    "    roles = df[role_col].dropna()\n",
    "    for i, role in enumerate(roles, 1):\n",
    "        print(f\"Response {i}: {role[:100]}{'...' if len(role) > 100 else ''}\")\n",
    "else:\n",
    "    print(\"Role column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c0da7",
   "metadata": {},
   "source": [
    "### Experience Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faac33a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:43.418186Z",
     "iopub.status.busy": "2025-10-30T11:45:43.418004Z",
     "iopub.status.idle": "2025-10-30T11:45:43.422530Z",
     "shell.execute_reply": "2025-10-30T11:45:43.421526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience levels:\n",
      "Response 1: > 5 Jahre\n",
      "Response 2: > 5 Jahre\n",
      "Response 3: > 5 Jahre\n",
      "Response 4: > 5 Jahre\n",
      "Response 5: > 5 Jahre\n",
      "Response 6: < 5 Jahre\n",
      "Response 7: > 5 Jahre\n",
      "Response 8: > 5 Jahre\n",
      "Response 9: > 5 Jahre\n",
      "Response 10: > 5 Jahre\n",
      "Response 11: > 5 Jahre\n",
      "Response 12: > 5 Jahre\n",
      "Response 13: > 5 Jahre\n",
      "Response 14: > 5 Jahre\n",
      "Response 15: > 5 Jahre\n",
      "Response 16: > 5 Jahre\n",
      "Response 17: > 5 Jahre\n",
      "Response 18: > 5 Jahre\n",
      "Response 19: > 5 Jahre\n",
      "Response 20: > 5 Jahre\n",
      "Response 21: < 5 Jahre\n",
      "Response 22: < 5 Jahre\n",
      "Response 23: > 5 Jahre\n",
      "Response 24: > 5 Jahre\n",
      "Response 25: > 5 Jahre\n",
      "Response 26: > 5 Jahre\n"
     ]
    }
   ],
   "source": [
    "# Find experience column\n",
    "experience_col = None\n",
    "for col in df.columns:\n",
    "    if 'Wie lange sind Sie' in col:\n",
    "        experience_col = col\n",
    "        break\n",
    "\n",
    "if experience_col:\n",
    "    print(\"Experience levels:\")\n",
    "    experiences = df[experience_col].dropna()\n",
    "    for i, exp in enumerate(experiences, 1):\n",
    "        print(f\"Response {i}: {exp}\")\n",
    "else:\n",
    "    print(\"Experience column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce8c912",
   "metadata": {},
   "source": [
    "### Communication Channels Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c875964f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:43.424419Z",
     "iopub.status.busy": "2025-10-30T11:45:43.424201Z",
     "iopub.status.idle": "2025-10-30T11:45:43.429022Z",
     "shell.execute_reply": "2025-10-30T11:45:43.428143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication channels used:\n",
      "Response 1: Online Formular;Telefon;Persönlich vor Ort;Email;\n",
      "Response 2: Email;Telefon;\n",
      "Response 3: Telefon;Persönlich vor Ort;\n",
      "Response 4: Telefon;Email;Online Formular;\n",
      "Response 5: Telefon;Email;Online Formular;\n",
      "Response 6: Telefon;Email;Persönlich vor Ort;\n",
      "Response 7: Email;Persönlich vor Ort;Telefon;\n",
      "Response 8: Telefon;Email;Persönlich vor Ort;Messanger Dienste wie What's App, Telegram etc.;\n",
      "Response 9: Telefon;Email;\n",
      "Response 10: Telefon;Email;Persönlich vor Ort;\n",
      "Response 11: Telefon;Email;Persönlich vor Ort;SMS zur Erinnerung;\n",
      "Response 12: Telefon;\n",
      "Response 13: Telefon;Email;Persönlich vor Ort;\n",
      "Response 14: Telefon;Persönlich vor Ort;\n",
      "Response 15: Telefon;Email;Persönlich vor Ort;\n",
      "Response 16: Telefon;Email;\n",
      "Response 17: Telefon;Email;Persönlich vor Ort;\n",
      "Response 18: Email;Telefon;Persönlich vor Ort;\n",
      "Response 19: Telefon;Email;\n",
      "Response 20: Telefon;Briefpost;\n",
      "Response 21: Telefon;Email;\n",
      "Response 22: Telefon;Email;\n",
      "Response 23: Telefon;Email;\n",
      "Response 24: Telefon;Email;\n",
      "Response 25: Telefon;Email;Messanger Dienste wie What's App, Telegram etc.;\n",
      "Response 26: Persönlich vor Ort;Email;Telefon;\n"
     ]
    }
   ],
   "source": [
    "# Find communication channels column\n",
    "comm_col = None\n",
    "for col in df.columns:\n",
    "    if 'Über welche Kanäle kontaktieren' in col:\n",
    "        comm_col = col\n",
    "        break\n",
    "\n",
    "if comm_col:\n",
    "    print(\"Communication channels used:\")\n",
    "    channels = df[comm_col].dropna()\n",
    "    for i, channel in enumerate(channels, 1):\n",
    "        print(f\"Response {i}: {channel}\")\n",
    "else:\n",
    "    print(\"Communication channels column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1236e2",
   "metadata": {},
   "source": [
    "### Software Usage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "558ba910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:43.430970Z",
     "iopub.status.busy": "2025-10-30T11:45:43.430785Z",
     "iopub.status.idle": "2025-10-30T11:45:43.436898Z",
     "shell.execute_reply": "2025-10-30T11:45:43.435829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Practice Management Software used:\n",
      "Response 1: ZaWin\n",
      "Response 2: ZaWin\n",
      "Response 3: ZaWIn\n",
      "Response 4: Aeskulap Kern Concept\n",
      "Response 5: ErgoDent\n",
      "Response 6: ZaWin\n",
      "Response 7: ZaWin\n",
      "Response 8: Ergodent, Sidexis\n",
      "Response 9: Zawin\n",
      "Response 10: ZaWin\n",
      "Response 11: Ergodent von CCS\n",
      "Response 12: Dentalmed XP\n",
      "Response 13: ZaWin\n",
      "Response 14: Dental med XP\n",
      "Response 15: Dent II \n",
      "Response 16: aeskulap\n",
      "Response 17: ProzessTeam\n",
      "Response 18: ZaWin\n",
      "Response 19: -\n",
      "Response 20: Keine\n",
      "Response 21: Zawin\n",
      "Response 22: ZaWin\n",
      "Response 23: Kern Concept - Aeskulap\n",
      "Response 24: Dental med XP\n",
      "Response 25: ZaWin\n",
      "Response 26: ZaWin\n",
      "\n",
      "Software usage summary:\n",
      "ZaWin: 13 mention(s)\n"
     ]
    }
   ],
   "source": [
    "# Find software column\n",
    "software_col = None\n",
    "for col in df.columns:\n",
    "    if 'Praxisverwaltungssoftware' in col:\n",
    "        software_col = col\n",
    "        break\n",
    "\n",
    "if software_col:\n",
    "    print(\"Practice Management Software used:\")\n",
    "    software = df[software_col].dropna()\n",
    "    for i, sw in enumerate(software, 1):\n",
    "        print(f\"Response {i}: {sw}\")\n",
    "        \n",
    "    # Simple analysis of mentioned software\n",
    "    software_mentions = {}\n",
    "    for sw in software:\n",
    "        sw_lower = sw.lower()\n",
    "        if 'zawin' in sw_lower:\n",
    "            software_mentions['ZaWin'] = software_mentions.get('ZaWin', 0) + 1\n",
    "        elif 'charly' in sw_lower:\n",
    "            software_mentions['Charly'] = software_mentions.get('Charly', 0) + 1\n",
    "        elif 'evident' in sw_lower:\n",
    "            software_mentions['Evident'] = software_mentions.get('Evident', 0) + 1\n",
    "    \n",
    "    if software_mentions:\n",
    "        print(\"\\nSoftware usage summary:\")\n",
    "        for sw, count in software_mentions.items():\n",
    "            print(f\"{sw}: {count} mention(s)\")\n",
    "else:\n",
    "    print(\"Software column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef486019",
   "metadata": {},
   "source": [
    "## 4. Key Challenges and Pain Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c56f2bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:43.438737Z",
     "iopub.status.busy": "2025-10-30T11:45:43.438551Z",
     "iopub.status.idle": "2025-10-30T11:45:43.444727Z",
     "shell.execute_reply": "2025-10-30T11:45:43.443712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 columns related to challenges:\n",
      "1. Was sind die grössten \"Störfaktoren\" oder Unterbrechungen bei Ihrer täglichen ad...\n",
      "   Responses:\n",
      "   Response 1: Die Aufgaben und Fragen die nur ich antworten kann\n",
      "   Response 2: Qualitätsmangement, Versicherungsanfragen\n",
      "   Response 3: das Personal\n",
      "   Response 4: Telefon, neuer Termin vergeben\n",
      "   Response 5: Personal, wo Fragen hat, Vorgesetzte die sonst noch Wünsche oder Probleme haben. Patienten die ganze Planung ändern möchten. \n",
      "   Response 6: Nächster Patient, Rückfragen von Mitarbeitern\n",
      "   Response 7: Die administrative Arbeit wird zwischen den Patientenbehandlungen oder Abends oder am Wochenende erledigt, es ist kein \"Bürotag\" bestimmt. Dadurch gib...\n",
      "   Response 8: MA kommen ständig was fragen, Telefone, Patientenanfragen vor Ort, Krankmeldungen, neue Planungen etc..\n",
      "   Response 9: Telefon, Patientennotfall\n",
      "   Response 10: Telefonate und Terminvergabe gleichzeitig, oder man hat einen recht anspruchsvollen Antrag an die Versicherung zu schreiben und es kommt zu Unterbrech...\n",
      "   Response 11: Unterbruch durch Telefon oder Terminvereinbarung, Patienten empfangen, Empfang ist sehr verzettelt, je nach Patientenaufkommen\n",
      "   Response 12: Telefon\n",
      "   Response 13: -\n",
      "   Response 14: Verschiedene Tarife\n",
      "Kostenvoranschläge für Ergänzungsleistung und Versicherungen\n",
      "   Response 15: Telefonische Anfragen von Kollegen, Patienten, Spitälern \n",
      "   Response 16: Telefonate, Zwischenfragen von Personal\n",
      "   Response 17: Versicherungsfälle\n",
      "   Response 18: Nur kurze Zeit zwischen jeweils zwei Patienten; somit grössere administrative Arbeiten nur morgens, mittags oder abends ind en \"Patientenpausen\" mögli...\n",
      "   Response 19: Patient will nach der Behandlung quatschen und braucht einen Psychoanalytiker \n",
      "   Response 20: Das sind keine Störfaktoren, dies ist Privatwirtschaft und wir sind ein Servicebetrieb. Nur öffentlich oder Versicherung können sich leisten Kunden zu...\n",
      "   Response 21: Telefon, Zimmerdesinfektion, administrativer Aufwand (KK, EL)\n",
      "   Response 22: Wenn ich davon weg gerufen werde oder Telefon anrufe.\n",
      "   Response 23: Patienten... :-)\n",
      "Internet - einfach abgelenkt\n",
      "   Response 24: Behandlung am Patient, Notfälle die zwischen den regulären Patienten behandelt werden müssen \n",
      "   Response 25: Genau: das Telefon klingelt, während man eine komplexe Abrechnung erstellt. \n",
      "   Response 26: Telefon, Personalanliegen und Sachfragen.\n",
      "\n",
      "2. Welche administrativen Aufgaben ausserhalb der direkten Patienteninteraktion emp...\n",
      "   Responses:\n",
      "   Response 1: Korrespondenz mit Krankenkassen / Versicherungen;Erstellung von Heil- und Kostenplänen;Dokumentation und Ablage;\n",
      "   Response 2: Korrespondenz mit Krankenkassen / Versicherungen;Erstellung von Heil- und Kostenplänen;Dokumentation und Ablage;\n",
      "   Response 3: Korrespondenz mit Krankenkassen / Versicherungen;Dokumentation und Ablage;\n",
      "   Response 4: Korrespondenz mit Krankenkassen / Versicherungen;Erstellung von Heil- und Kostenplänen;\n",
      "   Response 5: Korrespondenz mit Krankenkassen / Versicherungen;\n",
      "   Response 6: Korrespondenz mit Krankenkassen / Versicherungen;Erstellung von Heil- und Kostenplänen;\n",
      "   Response 7: Korrespondenz mit Krankenkassen / Versicherungen;Dokumentation und Ablage;Abrechnung mit Patienten;\n",
      "   Response 8: Korrespondenz mit Krankenkassen / Versicherungen;mit Ämter ist es am mühsamsten ;\n",
      "   Response 9: Korrespondenz mit Krankenkassen / Versicherungen;Erstellung von Heil- und Kostenplänen;\n",
      "   Response 10: Korrespondenz mit Krankenkassen / Versicherungen;Dokumentation und Ablage;\n",
      "   Response 11: Korrespondenz mit Krankenkassen / Versicherungen;Materialbestellungen und Lagerverwaltung;\n",
      "   Response 12: Korrespondenz mit Krankenkassen / Versicherungen;Materialbestellungen und Lagerverwaltung;\n",
      "   Response 13: Korrespondenz mit Krankenkassen / Versicherungen;Dokumentation und Ablage;QSS-Anpassungen;\n",
      "   Response 14: Korrespondenz mit Krankenkassen / Versicherungen;Dokumentation und Ablage;\n",
      "   Response 15: Korrespondenz mit Krankenkassen / Versicherungen;\n",
      "   Response 16: Korrespondenz mit Krankenkassen / Versicherungen;Dokumentation und Ablage;\n",
      "   Response 17: Korrespondenz mit Krankenkassen / Versicherungen;QSS;\n",
      "   Response 18: Korrespondenz mit Krankenkassen / Versicherungen;Korrespondenz mit Behörden (Sozialhilfe und EL);\n",
      "   Response 19: keine, gibt es bei mir nicht;\n",
      "   Response 20: Korrespondenz mit Krankenkassen / Versicherungen;Erstellung von Heil- und Kostenplänen;\n",
      "   Response 21: Korrespondenz mit Krankenkassen / Versicherungen;\n",
      "   Response 22: Korrespondenz mit Krankenkassen / Versicherungen;Erstellung von Heil- und Kostenplänen;\n",
      "   Response 23: Erstellung von Heil- und Kostenplänen;Korrespondenz mit Krankenkassen / Versicherungen;\n",
      "   Response 24: Korrespondenz mit Krankenkassen / Versicherungen;Dokumentation und Ablage;\n",
      "   Response 25: Korrespondenz mit Krankenkassen / Versicherungen;Materialbestellungen und Lagerverwaltung;\n",
      "   Response 26: Abrechnung mit Patienten;Korrespondenz mit Krankenkassen / Versicherungen;Materialbestellungen und Lagerverwaltung;\n",
      "\n",
      "3. Gibt es noch etwas Wichtiges zu Ihren administrativen Herausforderungen, das wir...\n",
      "   Responses:\n",
      "   Response 1: -\n",
      "   Response 2: es wird immer schlimmer und immer peinlicher , was wir alles machen müssen . Es ist nur noch mühsam ..  weniger \n",
      "   Response 3: Nein\n",
      "   Response 4: -\n",
      "   Response 5: Nein\n",
      "   Response 6: Nein\n",
      "   Response 7: Nein\n",
      "   Response 8: x\n",
      "   Response 9: nein\n",
      "   Response 10: -\n",
      "   Response 11: -\n",
      "   Response 12: nein\n",
      "   Response 13: Wenn die Größen der Praxen zunehmen und die Anforderungen weiter steigen benötigt es eine Fachkraft speziell für die Rezeption\n",
      "   Response 14: -\n",
      "   Response 15: -\n",
      "   Response 16: Nein\n",
      "   Response 17: Krankenkassen akzeptieren neuen TP-Wert nicht = Mehraufwand\n",
      "   Response 18: nein\n",
      "   Response 19: Jede Software hat Vor und Nachteile. Uebung macht den Meister. Mit wenig Versicherungskontakt zB. ist es immer von neuem Mühsam. Das liegt oft an der ...\n",
      "   Response 20: Das Einrichten eines (digitalen) QSS und Einhaltung aller Datenschutzrichtlinien wird uns zukünftig beschäftigen.\n",
      "   Response 21: Nein.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the main challenges/pain points columns\n",
    "challenge_cols = []\n",
    "for col in df.columns:\n",
    "    if any(keyword in col.lower() for keyword in ['störfaktoren', 'herausforderungen', 'mühsam', 'zeitaufwendig']):\n",
    "        challenge_cols.append(col)\n",
    "\n",
    "print(f\"Found {len(challenge_cols)} columns related to challenges:\")\n",
    "for i, col in enumerate(challenge_cols, 1):\n",
    "    print(f\"{i}. {col[:80]}{'...' if len(col) > 80 else ''}\")\n",
    "    \n",
    "    # Show responses for this challenge\n",
    "    responses = df[col].dropna()\n",
    "    if len(responses) > 0:\n",
    "        print(\"   Responses:\")\n",
    "        for j, response in enumerate(responses, 1):\n",
    "            print(f\"   Response {j}: {response[:150]}{'...' if len(response) > 150 else ''}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3debd9",
   "metadata": {},
   "source": [
    "## 5. Digital Transformation Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19f17447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:43.446598Z",
     "iopub.status.busy": "2025-10-30T11:45:43.446404Z",
     "iopub.status.idle": "2025-10-30T11:45:43.452964Z",
     "shell.execute_reply": "2025-10-30T11:45:43.452015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 columns related to digital transformation:\n",
      "1. Welche anderen digitalen Tools oder Programme nutzen Sie regelmässig im administ...\n",
      "   Responses:\n",
      "   Response 1: BESR\n",
      "   Response 2: Trios, Rö-Software Orange\n",
      "   Response 3: alle die wir benötigen \n",
      "   Response 4: Mediport, Byzz\n",
      "   Response 5: Outlook, Swisstransfer, Condent\n",
      "   Response 6: Digitale Anamnese am Tablet, Scanner der Sterilisationsetiketten, Nostic, Onlineagenda, Materialbestellung Novadent\n",
      "   Response 7: Excel, Word, Acrobat, OnyxCeph, Sidexis, Outlook\n",
      "   Response 8: Anyguard, Diagnokat, Nostic, Q.Wiki\n",
      "   Response 9: Digit. Röntgen, Cerec\n",
      "   Response 10: Romexis (Röntgenprogramm)\n",
      "Onyx Ceph (Auswertungsprogramm von Röntgen und Modellen)\n",
      "Outlook\n",
      "   Response 11: Abaweb, MedMonitor, Sidexis, DS Core\n",
      "   Response 12: dig. RX-Programm von Curaden\n",
      "   Response 13: Sidexis /Outlook/ Office-Produkte\n",
      "   Response 14: Excel, Word\n",
      "   Response 15: Windows, Carestream CS, Mailprogramme, Abrechnungsprogramme (Mediport)\n",
      "   Response 16: Diagnocat\n",
      "   Response 17: viele... SMOP; iDixel, SOPRO, alles von Apple\n",
      "   Response 18: Outlook, Word, Excel\n",
      "   Response 19: Scanner\n",
      "   Response 20: PC\n",
      "   Response 21: Rx-Programme (Onyx, Romexis)\n",
      "   Response 22: keine\n",
      "   Response 23: Outlook Agenda und Mail sowie Mail HIN\n",
      "Digora , Sidexis, Intraoral Scanner 3Shape\n",
      "   Response 24: -\n",
      "   Response 25: Microsoft OneNote (\"white-board\"), Tablets: Anamnese elektronisch ausfüllen und signieren, Validierung der Sterilisationsvorgänge. \n",
      "DS Core-Plattform:...\n",
      "   Response 26: MedMonitor (QSS), Zeiterfassung (Portos), Schichtverwaltung (Schichty), SecureSafe, E-Banking.\n",
      "\n",
      "2. Wo sehen Sie persönlich den grössten Mehrwert für digitale Unterstützung, der Ih...\n",
      "   Responses:\n",
      "   Response 1: Zeitgewinnung\n",
      "   Response 2: -\n",
      "   Response 3: wie arbeiten klinisch am Patienten, da hilft uns das Digitale gar nichts..   und wenn was nicht geht, sind es  sehr oft das digitale und die PCs\n",
      "   Response 4: Digital ist alles gut und recht, aber leider gibt es sehr vieles was man persönlich erledigen muss\n",
      "   Response 5: Die Kommunikation mit den Versicherungen ist wirklich lästig und zeitaufwändig. Es sollte eine direkte Nummer geben für Ärzte und Zahnärzte\n",
      "   Response 6: QSS Listen\n",
      "   Response 7: Automatisierte QSS\n",
      "   Response 8: Telefonie, Korrespondenz durch KI\n",
      "   Response 9: Automat. Kostenvoranschlag und Sozialformular ausfüllen\n",
      "   Response 10: -\n",
      "   Response 11: weiss nicht\n",
      "   Response 12: nicht wirklich realistisch\n",
      "   Response 13: -\n",
      "   Response 14: -\n",
      "   Response 15: weniger Digitalität\n",
      "   Response 16: Wenn die Softwareunternehmen gut vernetzt sind und alle Aktivitäten kombiniert werden können ohne dass wie manchmal noch notwendig zweigleisig gefahre...\n",
      "   Response 17: es gibt QSS-unterstützende Programme, die aber sehr teuer sind und Micromanagement bringen\n",
      "   Response 18: Ich denke, ich bin schon sehr \"digital\" am arbeiten. Schlussendlich braucht es aber den Menschen, der den Patienten mit seinen Bedürfnissen und Wünsch...\n",
      "   Response 19: Zeitersprnis bei Befundung mit KI\n",
      "   Response 20: In einer Solopraxis bringt digitale Unterstützung nur Mehrarbeit und niedrigeren Stundenumsatz.\n",
      "   Response 21: gut funktionierende Online-Agenda\n",
      "   Response 22: keinen, im Gegenteil es erschwert einiges.\n",
      "   Response 23: Für mich: DAs was ich habe:\n",
      "Agenda, Abrechnung und Patienten Software mit KoVo, Digitales Rx und Scan. \n",
      "Digitale KG macht mich nicht schneller nur ärm...\n",
      "   Response 24: automatische Text-Eingabe \n",
      "   Response 25: Digitales Röntgen: Befundung digital. Zukünftig per KI. \n",
      "   Response 26: Nicht klar ersichtlich.\n",
      "\n",
      "3. Bemerken Sie eine steigende Nachfrage nach digitalen Kontaktmöglichkeiten (z.B. ...\n",
      "   Responses:\n",
      "   Response 1: Ja, deutlich\n",
      "   Response 2: Ja, ein wenig\n",
      "   Response 3: Nein, nicht wirklich\n",
      "   Response 4: Nein, nicht wirklich\n",
      "   Response 5: Ja, deutlich\n",
      "   Response 6: Ja, ein wenig\n",
      "   Response 7: Ja, ein wenig\n",
      "   Response 8: Ja, deutlich\n",
      "   Response 9: Ja, ein wenig\n",
      "   Response 10: Ja, ein wenig\n",
      "   Response 11: Ja, deutlich\n",
      "   Response 12: Ja, ein wenig\n",
      "   Response 13: Nein, nicht wirklich\n",
      "   Response 14: Nein, nicht wirklich\n",
      "   Response 15: Nein, nicht wirklich\n",
      "   Response 16: Nein, nicht wirklich\n",
      "   Response 17: Nein, nicht wirklich\n",
      "   Response 18: Ja, ein wenig\n",
      "   Response 19: Nein, nicht wirklich\n",
      "   Response 20: Nein, nicht wirklich\n",
      "   Response 21: Ja, ein wenig\n",
      "   Response 22: Ja, deutlich\n",
      "   Response 23: Nein, nicht wirklich\n",
      "   Response 24: Nein, nicht wirklich\n",
      "   Response 25: Nein, nicht wirklich\n",
      "   Response 26: Ja, deutlich\n",
      "\n",
      "4. Die magische Assistenz: Stellen Sie sich vor, Sie hätten einen perfekten digital...\n",
      "   Responses:\n",
      "   Response 1: Recallwesen, E-mail verwaltung, Agenda\n",
      "   Response 2: Spracheingabe (Krankengeschichte), Spracheingabe Abrechnung, Dokumentation im allgemeinen\n",
      "   Response 3: ich will keinen digitalen Assistenten \n",
      "   Response 4: Überweisungen schreiben anhand von 3 Stichworten\n",
      "   Response 5: Gesamte Korrespondenz und Abklärungen mit Versicherungen\n",
      "   Response 6: Abrechnung und Kommunikation mit Versicherungen, Mails beantworten, Mahnwesen\n",
      "   Response 7: Terminvergabe, Rechnungswesen mit Mahnungen und Betreibungen, KG-Einträge machen\n",
      "   Response 8: Telefonie reicht schon\n",
      "   Response 9: Administration, Automatischer Recalldienst, \n",
      "   Response 10: - Abwicklung der Telefonate\n",
      "   Response 11: Terminvereinbarungen und -änderungen automatisch\n",
      "   Response 12: autom. Rechnung zu schreiben :)\n",
      "   Response 13: Ersatz der Dentalassistentin\n",
      "   Response 14: Kostenvoranschläge für Ergänzungsleistung \n",
      "   Response 15: Wichtiges von Unwichtigem unterscheiden\n",
      "   Response 16: perfekte Terminierung, freundliche Bedienung auch unfreundlicher Kunden, immer erreichbar\n",
      "   Response 17: QSS Hygiene\n",
      "Korrespondenz mit Versicherungen\n",
      "Planungen\n",
      "   Response 18: QA, alle Korrespondenz, IT/EDV-Probleme lösen\n",
      "   Response 19: wir haben alles...\n",
      "   Response 20: Caffè zu machen\n",
      "   Response 21: Terminvergabe \n",
      "   Response 22: nörgelnde Patienten zu beruhigen, ansonsten keine\n",
      "   Response 23: Umfragen beantworten... :-)\n",
      "vgl Frage 25!\n",
      "Abrechnung mit Behörden inkl Kostenvoranschläge etc. und Begleitbriefe etc. etc, Rücküberweisungen automatis...\n",
      "   Response 24: Grober KG-Eintrag, Vorbereitung von Formularen, Rezepte  \n",
      "   Response 25: Behandlungsplanung (inkl. KV-Erstellung), Recall (per Mail und Telefonat), Inventarliste (inkl. Nachbestellung)\n",
      "   Response 26: 1. Erledigung der Dokumentationspflicht (siehe 25.)\n",
      "2. Systemunterstützte Materialbestellung\n",
      "3. E-Mailbearbeitung\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find digital transformation related columns\n",
    "digital_cols = []\n",
    "for col in df.columns:\n",
    "    if any(keyword in col.lower() for keyword in ['digital', 'online', 'automatisch', 'ki', 'assistent']):\n",
    "        digital_cols.append(col)\n",
    "\n",
    "print(f\"Found {len(digital_cols)} columns related to digital transformation:\")\n",
    "for i, col in enumerate(digital_cols, 1):\n",
    "    print(f\"{i}. {col[:80]}{'...' if len(col) > 80 else ''}\")\n",
    "    \n",
    "    # Show responses\n",
    "    responses = df[col].dropna()\n",
    "    if len(responses) > 0:\n",
    "        print(\"   Responses:\")\n",
    "        for j, response in enumerate(responses, 1):\n",
    "            print(f\"   Response {j}: {response[:150]}{'...' if len(response) > 150 else ''}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462a3682",
   "metadata": {},
   "source": [
    "## 7. Graphical Response Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42dd75e",
   "metadata": {},
   "source": [
    "### Survey Completion Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8bbdb86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:43.454956Z",
     "iopub.status.busy": "2025-10-30T11:45:43.454765Z",
     "iopub.status.idle": "2025-10-30T11:45:43.609871Z",
     "shell.execute_reply": "2025-10-30T11:45:43.608824Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enhanced completion time visualization\n",
    "if 'completion_duration' in df.columns:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Subplot 1: Histogram of completion times\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.hist(df['completion_duration'].dropna(), bins=10, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    plt.title('Distribution of Survey Completion Times')\n",
    "    plt.xlabel('Completion Time (minutes)')\n",
    "    plt.ylabel('Number of Responses')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Subplot 2: Box plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.boxplot(df['completion_duration'].dropna(), patch_artist=True, \n",
    "                boxprops=dict(facecolor='lightgreen', alpha=0.7))\n",
    "    plt.title('Completion Time Distribution')\n",
    "    plt.ylabel('Time (minutes)')\n",
    "    plt.xticks([1], ['All Responses'])\n",
    "    \n",
    "    # Subplot 3: Timeline of responses\n",
    "    plt.subplot(1, 3, 3)\n",
    "    if 'Startzeit' in df.columns:\n",
    "        response_times = df['Startzeit'].dt.hour.value_counts().sort_index()\n",
    "        plt.bar(response_times.index, response_times.values, color='orange', alpha=0.7)\n",
    "        plt.title('Response Times by Hour')\n",
    "        plt.xlabel('Hour of Day')\n",
    "        plt.ylabel('Number of Responses')\n",
    "        plt.xticks(range(0, 24, 2))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Completion duration data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b613c80",
   "metadata": {},
   "source": [
    "### Professional Role Analysis with Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13e55a9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:43.612048Z",
     "iopub.status.busy": "2025-10-30T11:45:43.611829Z",
     "iopub.status.idle": "2025-10-30T11:45:43.748933Z",
     "shell.execute_reply": "2025-10-30T11:45:43.747978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role Analysis Summary:\n",
      "- Praxisassistentin: 2 respondent(s)\n",
      "- Zahnarzt/Zahnärztin: 10 respondent(s)\n",
      "- Praxisleiter: 11 respondent(s)\n",
      "- Koordination: 3 respondent(s)\n",
      "- Empfang: 1 respondent(s)\n"
     ]
    }
   ],
   "source": [
    "# Role analysis with advanced text processing and visualization\n",
    "role_col = None\n",
    "for col in df.columns:\n",
    "    if 'Rolle in der Praxis' in col:\n",
    "        role_col = col\n",
    "        break\n",
    "\n",
    "if role_col and not df[role_col].dropna().empty:\n",
    "    # Extract key role types from responses\n",
    "    role_keywords = {\n",
    "        'Praxisassistentin': ['assistentin', 'assistent'],\n",
    "        'Zahnarzt/Zahnärztin': ['zahnarzt', 'zahnärztin', 'arzt', 'ärztin'],\n",
    "        'Praxisleiter': ['leiter', 'leiterin', 'chef', 'inhaber'],\n",
    "        'Koordination': ['koordin', 'organisation', 'planung'],\n",
    "        'Empfang': ['empfang', 'rezeption', 'front office']\n",
    "    }\n",
    "    \n",
    "    role_counts = {role: 0 for role in role_keywords.keys()}\n",
    "    \n",
    "    for response in df[role_col].dropna():\n",
    "        response_lower = response.lower()\n",
    "        for role, keywords in role_keywords.items():\n",
    "            if any(keyword in response_lower for keyword in keywords):\n",
    "                role_counts[role] += 1\n",
    "    \n",
    "    # Create visualizations\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Pie chart of roles\n",
    "    plt.subplot(2, 2, 1)\n",
    "    valid_roles = {k: v for k, v in role_counts.items() if v > 0}\n",
    "    if valid_roles:\n",
    "        colors = plt.cm.Set3(range(len(valid_roles)))\n",
    "        plt.pie(valid_roles.values(), labels=valid_roles.keys(), autopct='%1.1f%%', \n",
    "                colors=colors, startangle=90)\n",
    "        plt.title('Professional Roles Distribution')\n",
    "    \n",
    "    # Bar chart of roles\n",
    "    plt.subplot(2, 2, 2)\n",
    "    if valid_roles:\n",
    "        bars = plt.bar(valid_roles.keys(), valid_roles.values(), \n",
    "                      color=plt.cm.Set3(range(len(valid_roles))))\n",
    "        plt.title('Professional Roles Count')\n",
    "        plt.xlabel('Role Type')\n",
    "        plt.ylabel('Number of Respondents')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, count in zip(bars, valid_roles.values()):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05, \n",
    "                     f'{count}', ha='center', va='bottom')\n",
    "    \n",
    "    # Word frequency analysis\n",
    "    plt.subplot(2, 1, 2)\n",
    "    from collections import Counter\n",
    "    import re\n",
    "    \n",
    "    # Combine all role descriptions\n",
    "    all_text = ' '.join(df[role_col].dropna().astype(str))\n",
    "    # Extract meaningful words (German)\n",
    "    words = re.findall(r'\\b[a-zA-ZäöüÄÖÜß]{4,}\\b', all_text.lower())\n",
    "    \n",
    "    # Filter out common stopwords and keep relevant terms\n",
    "    stopwords = {'sind', 'sich', 'eine', 'einen', 'einer', 'mich', 'für', 'und', 'der', 'die', 'das', 'ich', 'bin', 'haben', 'mit', 'von', 'auf', 'als', 'auch', 'oder'}\n",
    "    relevant_words = [word for word in words if word not in stopwords and len(word) > 3]\n",
    "    \n",
    "    word_freq = Counter(relevant_words).most_common(10)\n",
    "    \n",
    "    if word_freq:\n",
    "        words, counts = zip(*word_freq)\n",
    "        plt.barh(range(len(words)), counts, color='lightcoral')\n",
    "        plt.yticks(range(len(words)), words)\n",
    "        plt.title('Most Frequent Words in Role Descriptions')\n",
    "        plt.xlabel('Frequency')\n",
    "        plt.gca().invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Role Analysis Summary:\")\n",
    "    for role, count in role_counts.items():\n",
    "        if count > 0:\n",
    "            print(f\"- {role}: {count} respondent(s)\")\n",
    "else:\n",
    "    print(\"Role data not available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f9a35",
   "metadata": {},
   "source": [
    "### Communication Channels Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97837f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:43.751180Z",
     "iopub.status.busy": "2025-10-30T11:45:43.750973Z",
     "iopub.status.idle": "2025-10-30T11:45:43.911588Z",
     "shell.execute_reply": "2025-10-30T11:45:43.910629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication Channel Analysis:\n",
      "- Telefon: 26 mentions (100.0% of responses)\n",
      "- E-Mail: 22 mentions (84.6% of responses)\n",
      "- SMS: 1 mentions (3.8% of responses)\n",
      "- Persönlich: 13 mentions (50.0% of responses)\n",
      "- Brief/Post: 1 mentions (3.8% of responses)\n"
     ]
    }
   ],
   "source": [
    "# Communication channels analysis with visualizations\n",
    "comm_col = None\n",
    "for col in df.columns:\n",
    "    if 'Über welche Kanäle kontaktieren' in col:\n",
    "        comm_col = col\n",
    "        break\n",
    "\n",
    "if comm_col and not df[comm_col].dropna().empty:\n",
    "    # Extract communication channels from responses\n",
    "    channel_keywords = {\n",
    "        'Telefon': ['telefon', 'anruf', 'phone'],\n",
    "        'E-Mail': ['email', 'e-mail', 'mail'],\n",
    "        'SMS': ['sms', 'text', 'nachricht'],\n",
    "        'WhatsApp': ['whatsapp', 'messenger'],\n",
    "        'Persönlich': ['persönlich', 'direkt', 'vor ort'],\n",
    "        'Brief/Post': ['brief', 'post', 'schriftlich']\n",
    "    }\n",
    "    \n",
    "    channel_counts = {channel: 0 for channel in channel_keywords.keys()}\n",
    "    \n",
    "    for response in df[comm_col].dropna():\n",
    "        response_lower = response.lower()\n",
    "        for channel, keywords in channel_keywords.items():\n",
    "            if any(keyword in response_lower for keyword in keywords):\n",
    "                channel_counts[channel] += 1\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Main pie chart\n",
    "    plt.subplot(2, 3, 1)\n",
    "    valid_channels = {k: v for k, v in channel_counts.items() if v > 0}\n",
    "    if valid_channels:\n",
    "        colors = plt.cm.Set2(range(len(valid_channels)))\n",
    "        wedges, texts, autotexts = plt.pie(valid_channels.values(), labels=valid_channels.keys(), \n",
    "                                          autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "        plt.title('Communication Channels Usage')\n",
    "    \n",
    "    # Horizontal bar chart\n",
    "    plt.subplot(2, 3, 2)\n",
    "    if valid_channels:\n",
    "        y_pos = range(len(valid_channels))\n",
    "        bars = plt.barh(y_pos, list(valid_channels.values()), \n",
    "                       color=plt.cm.Set2(range(len(valid_channels))))\n",
    "        plt.yticks(y_pos, list(valid_channels.keys()))\n",
    "        plt.xlabel('Number of Mentions')\n",
    "        plt.title('Communication Channels Frequency')\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, (bar, count) in enumerate(zip(bars, valid_channels.values())):\n",
    "            plt.text(bar.get_width() + 0.05, bar.get_y() + bar.get_height()/2, \n",
    "                     f'{count}', ha='left', va='center')\n",
    "    \n",
    "    # Stacked bar for comparison\n",
    "    plt.subplot(2, 3, 3)\n",
    "    if valid_channels:\n",
    "        total_responses = len(df[comm_col].dropna())\n",
    "        percentages = [count/total_responses*100 for count in valid_channels.values()]\n",
    "        plt.bar(['Communication Channels'], [100], color='lightgray', alpha=0.3)\n",
    "        \n",
    "        bottom = 0\n",
    "        for i, (channel, percentage) in enumerate(zip(valid_channels.keys(), percentages)):\n",
    "            plt.bar(['Communication Channels'], [percentage], bottom=bottom, \n",
    "                   label=channel, color=plt.cm.Set2(i))\n",
    "            bottom += percentage\n",
    "        \n",
    "        plt.ylabel('Percentage')\n",
    "        plt.title('Channel Usage Distribution')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Communication preferences analysis\n",
    "    plt.subplot(2, 1, 2)\n",
    "    if len(df[comm_col].dropna()) > 0:\n",
    "        # Create a more detailed analysis\n",
    "        response_analysis = []\n",
    "        for idx, response in enumerate(df[comm_col].dropna()):\n",
    "            channels_used = []\n",
    "            for channel, keywords in channel_keywords.items():\n",
    "                if any(keyword in response.lower() for keyword in keywords):\n",
    "                    channels_used.append(channel)\n",
    "            response_analysis.append({\n",
    "                'Response': idx + 1,\n",
    "                'Channels': channels_used,\n",
    "                'Channel_Count': len(channels_used)\n",
    "            })\n",
    "        \n",
    "        # Plot channel combination frequency\n",
    "        channel_counts_per_response = [item['Channel_Count'] for item in response_analysis]\n",
    "        unique_counts = list(set(channel_counts_per_response))\n",
    "        count_frequency = [channel_counts_per_response.count(count) for count in unique_counts]\n",
    "        \n",
    "        plt.bar(unique_counts, count_frequency, color='steelblue', alpha=0.7)\n",
    "        plt.xlabel('Number of Communication Channels per Response')\n",
    "        plt.ylabel('Number of Responses')\n",
    "        plt.title('Multi-Channel Communication Usage')\n",
    "        plt.xticks(unique_counts)\n",
    "        \n",
    "        # Add value labels\n",
    "        for x, y in zip(unique_counts, count_frequency):\n",
    "            plt.text(x, y + 0.05, f'{y}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Communication Channel Analysis:\")\n",
    "    for channel, count in channel_counts.items():\n",
    "        if count > 0:\n",
    "            percentage = (count / len(df[comm_col].dropna())) * 100\n",
    "            print(f\"- {channel}: {count} mentions ({percentage:.1f}% of responses)\")\n",
    "else:\n",
    "    print(\"Communication channels data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b297ce",
   "metadata": {},
   "source": [
    "### Software Usage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b420162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:43.913780Z",
     "iopub.status.busy": "2025-10-30T11:45:43.913579Z",
     "iopub.status.idle": "2025-10-30T11:45:44.108179Z",
     "shell.execute_reply": "2025-10-30T11:45:44.107178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software Usage Analysis Summary:\n",
      "Total responses analyzed: 26\n",
      "- ZaWin: 13 practices (50.0%)\n",
      "- Andere/Custom: 13 practices (50.0%)\n",
      "\n",
      "Software Market Insights:\n",
      "- Most popular software: ZaWin (13 users)\n",
      "- Software diversity: 2 different systems mentioned\n",
      "- Market concentration: Top software has 50.0% market share\n"
     ]
    }
   ],
   "source": [
    "# Software usage analysis with comprehensive visualizations\n",
    "software_col = None\n",
    "for col in df.columns:\n",
    "    if 'Praxisverwaltungssoftware' in col:\n",
    "        software_col = col\n",
    "        break\n",
    "\n",
    "if software_col and not df[software_col].dropna().empty:\n",
    "    # Extract software mentions from responses\n",
    "    software_keywords = {\n",
    "        'ZaWin': ['zawin', 'za-win'],\n",
    "        'Charly': ['charly'],\n",
    "        'Evident': ['evident'],\n",
    "        'Dampsoft': ['dampsoft', 'damp soft'],\n",
    "        'Carestream': ['carestream'],\n",
    "        'OpenDental': ['opendental', 'open dental'],\n",
    "        'PracticeWorks': ['practiceworks', 'practice works'],\n",
    "        'Andere/Custom': ['custom', 'eigenentwicklung', 'selbst']\n",
    "    }\n",
    "    \n",
    "    software_counts = {software: 0 for software in software_keywords.keys()}\n",
    "    \n",
    "    for response in df[software_col].dropna():\n",
    "        response_lower = response.lower()\n",
    "        found_software = False\n",
    "        for software, keywords in software_keywords.items():\n",
    "            if any(keyword in response_lower for keyword in keywords):\n",
    "                software_counts[software] += 1\n",
    "                found_software = True\n",
    "                break\n",
    "        \n",
    "        # If no specific software found, categorize as \"Andere/Custom\"\n",
    "        if not found_software and response.strip():\n",
    "            software_counts['Andere/Custom'] += 1\n",
    "    \n",
    "    # Create comprehensive software analysis visualization\n",
    "    plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # Main software distribution pie chart\n",
    "    plt.subplot(2, 3, 1)\n",
    "    valid_software = {k: v for k, v in software_counts.items() if v > 0}\n",
    "    if valid_software:\n",
    "        colors = plt.cm.Set1(range(len(valid_software)))\n",
    "        wedges, texts, autotexts = plt.pie(valid_software.values(), labels=valid_software.keys(), \n",
    "                                          autopct='%1.1f%%', colors=colors, startangle=45)\n",
    "        plt.title('Practice Management Software Distribution')\n",
    "    \n",
    "    # Horizontal bar chart\n",
    "    plt.subplot(2, 3, 2)\n",
    "    if valid_software:\n",
    "        y_pos = range(len(valid_software))\n",
    "        bars = plt.barh(y_pos, list(valid_software.values()), \n",
    "                       color=plt.cm.Set1(range(len(valid_software))))\n",
    "        plt.yticks(y_pos, list(valid_software.keys()))\n",
    "        plt.xlabel('Number of Practices')\n",
    "        plt.title('Software Usage Frequency')\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, (bar, count) in enumerate(zip(bars, valid_software.values())):\n",
    "            plt.text(bar.get_width() + 0.05, bar.get_y() + bar.get_height()/2, \n",
    "                     f'{count}', ha='left', va='center')\n",
    "    \n",
    "    # Market share visualization\n",
    "    plt.subplot(2, 3, 3)\n",
    "    if valid_software:\n",
    "        total_software_users = sum(valid_software.values())\n",
    "        market_share = [(count/total_software_users)*100 for count in valid_software.values()]\n",
    "        \n",
    "        plt.bar(range(len(valid_software)), market_share, \n",
    "                color=plt.cm.Set1(range(len(valid_software))))\n",
    "        plt.xlabel('Software')\n",
    "        plt.ylabel('Market Share (%)')\n",
    "        plt.title('Software Market Share')\n",
    "        plt.xticks(range(len(valid_software)), list(valid_software.keys()), rotation=45, ha='right')\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, percentage in enumerate(market_share):\n",
    "            plt.text(i, percentage + 1, f'{percentage:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # Software satisfaction/integration analysis (placeholder for future data)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    \n",
    "    # Create a comparison chart showing software mentions vs. total responses\n",
    "    software_data = []\n",
    "    total_responses = len(df[software_col].dropna())\n",
    "    \n",
    "    for software, count in valid_software.items():\n",
    "        software_data.append({\n",
    "            'Software': software,\n",
    "            'Users': count,\n",
    "            'Market_Share': (count/total_responses)*100 if total_responses > 0 else 0\n",
    "        })\n",
    "    \n",
    "    if software_data:\n",
    "        software_df = pd.DataFrame(software_data)\n",
    "        \n",
    "        # Create a detailed comparison\n",
    "        x_pos = range(len(software_df))\n",
    "        bars1 = plt.bar([x - 0.2 for x in x_pos], software_df['Users'], 0.4, \n",
    "                       label='Number of Users', color='steelblue', alpha=0.7)\n",
    "        bars2 = plt.bar([x + 0.2 for x in x_pos], software_df['Market_Share'], 0.4, \n",
    "                       label='Market Share (%)', color='orange', alpha=0.7)\n",
    "        \n",
    "        plt.xlabel('Practice Management Software')\n",
    "        plt.ylabel('Count / Percentage')\n",
    "        plt.title('Software Usage: Users vs Market Share')\n",
    "        plt.xticks(x_pos, software_df['Software'], rotation=45, ha='right')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar in bars1:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05, \n",
    "                     f'{int(bar.get_height())}', ha='center', va='bottom')\n",
    "        for bar in bars2:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05, \n",
    "                     f'{bar.get_height():.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Software Usage Analysis Summary:\")\n",
    "    print(f\"Total responses analyzed: {len(df[software_col].dropna())}\")\n",
    "    for software, count in software_counts.items():\n",
    "        if count > 0:\n",
    "            percentage = (count / len(df[software_col].dropna())) * 100\n",
    "            print(f\"- {software}: {count} practices ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Additional software insights\n",
    "    print(f\"\\nSoftware Market Insights:\")\n",
    "    if valid_software:\n",
    "        top_software = max(valid_software.items(), key=lambda x: x[1])\n",
    "        print(f\"- Most popular software: {top_software[0]} ({top_software[1]} users)\")\n",
    "        print(f\"- Software diversity: {len(valid_software)} different systems mentioned\")\n",
    "        print(f\"- Market concentration: Top software has {(top_software[1]/sum(valid_software.values()))*100:.1f}% market share\")\n",
    "else:\n",
    "    print(\"Software data not available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd3e65",
   "metadata": {},
   "source": [
    "### Pain Points and Challenges Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5514e0e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:44.110724Z",
     "iopub.status.busy": "2025-10-30T11:45:44.110523Z",
     "iopub.status.idle": "2025-10-30T11:45:44.557875Z",
     "shell.execute_reply": "2025-10-30T11:45:44.556734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Challenge Analysis Summary:\n",
      "Total challenge responses analyzed: 73\n",
      "Number of challenge categories: 3\n",
      "\n",
      "Top Challenge Themes:\n",
      "- Telefon/Unterbrechungen: 13 mentions (17.8%)\n",
      "- Dokumentation: 9 mentions (12.3%)\n",
      "- Terminplanung: 5 mentions (6.8%)\n",
      "- Manuelle Arbeit: 3 mentions (4.1%)\n",
      "- Zeitmanagement: 2 mentions (2.7%)\n",
      "- Technische Probleme: 1 mentions (1.4%)\n",
      "\n",
      "Most frequently mentioned challenge words:\n",
      "- 'versicherungen': 26 times\n",
      "- 'korrespondenz': 26 times\n",
      "- 'krankenkassen': 26 times\n",
      "- 'patienten': 9 times\n",
      "- 'dokumentation': 9 times\n"
     ]
    }
   ],
   "source": [
    "# Pain points and challenges analysis with visualizations\n",
    "from collections import Counter\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Find challenge-related columns\n",
    "challenge_keywords = ['störfaktoren', 'herausforderungen', 'mühsam', 'zeitaufwendig', 'schwierig', 'problem']\n",
    "challenge_cols = []\n",
    "for col in df.columns:\n",
    "    if any(keyword in col.lower() for keyword in challenge_keywords):\n",
    "        challenge_cols.append(col)\n",
    "\n",
    "if challenge_cols:\n",
    "    # Combine all challenge responses\n",
    "    all_challenges = []\n",
    "    for col in challenge_cols:\n",
    "        responses = df[col].dropna()\n",
    "        all_challenges.extend(responses.tolist())\n",
    "    \n",
    "    if all_challenges:\n",
    "        # Extract key challenge themes\n",
    "        challenge_themes = {\n",
    "            'Telefon/Unterbrechungen': ['telefon', 'anruf', 'unterbrechung', 'störung', 'klingeln'],\n",
    "            'Zeitmanagement': ['zeit', 'zeitaufwendig', 'zeitraubend', 'schnell', 'stress'],\n",
    "            'Manuelle Arbeit': ['manuell', 'hand', 'übertragen', 'kopieren', 'eingeben'],\n",
    "            'Kommunikation': ['kommunikation', 'information', 'weiterleitung', 'abstimmung'],\n",
    "            'Technische Probleme': ['system', 'software', 'technik', 'computer', 'fehler'],\n",
    "            'Dokumentation': ['dokumentation', 'notizen', 'aufschreiben', 'festhalten'],\n",
    "            'Terminplanung': ['termin', 'planung', 'kalender', 'buchung', 'vereinbarung']\n",
    "        }\n",
    "        \n",
    "        theme_counts = {theme: 0 for theme in challenge_themes.keys()}\n",
    "        \n",
    "        for response in all_challenges:\n",
    "            response_lower = response.lower()\n",
    "            for theme, keywords in challenge_themes.items():\n",
    "                if any(keyword in response_lower for keyword in keywords):\n",
    "                    theme_counts[theme] += 1\n",
    "        \n",
    "        # Create comprehensive visualization\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 14))\n",
    "        \n",
    "        # Theme frequency pie chart\n",
    "        valid_themes = {k: v for k, v in theme_counts.items() if v > 0}\n",
    "        if valid_themes:\n",
    "            colors = plt.cm.Set3(range(len(valid_themes)))\n",
    "            wedges, texts, autotexts = ax1.pie(valid_themes.values(), labels=valid_themes.keys(), \n",
    "                                              autopct='%1.1f%%', colors=colors, startangle=45)\n",
    "            ax1.set_title('Main Challenge Themes Distribution')\n",
    "        \n",
    "        # Horizontal bar chart\n",
    "        if valid_themes:\n",
    "            y_pos = range(len(valid_themes))\n",
    "            bars = ax2.barh(y_pos, list(valid_themes.values()), \n",
    "                           color=plt.cm.Set3(range(len(valid_themes))))\n",
    "            ax2.set_yticks(y_pos)\n",
    "            ax2.set_yticklabels(list(valid_themes.keys()))\n",
    "            ax2.set_xlabel('Number of Mentions')\n",
    "            ax2.set_title('Challenge Frequency Analysis')\n",
    "            \n",
    "            # Add value labels\n",
    "            for i, (bar, count) in enumerate(zip(bars, valid_themes.values())):\n",
    "                ax2.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2, \n",
    "                         f'{count}', ha='left', va='center')\n",
    "        \n",
    "        # Word frequency analysis\n",
    "        all_text = ' '.join(all_challenges).lower()\n",
    "        words = re.findall(r'\\b[a-zA-ZäöüÄÖÜß]{4,}\\b', all_text)\n",
    "        \n",
    "        # German stopwords\n",
    "        german_stopwords = {\n",
    "            'sind', 'sich', 'eine', 'einen', 'einer', 'mich', 'für', 'und', 'der', 'die', 'das', \n",
    "            'ich', 'bin', 'haben', 'mit', 'von', 'auf', 'als', 'auch', 'oder', 'aber', 'wenn', \n",
    "            'wird', 'werden', 'wurde', 'kann', 'könnte', 'sollte', 'muss', 'müssen', 'immer', \n",
    "            'sehr', 'noch', 'mehr', 'gibt', 'geht', 'kommt', 'macht', 'sein', 'seine', 'seiner'\n",
    "        }\n",
    "        \n",
    "        relevant_words = [word for word in words if word not in german_stopwords and len(word) > 3]\n",
    "        word_freq = Counter(relevant_words).most_common(15)\n",
    "        \n",
    "        if word_freq:\n",
    "            words_list, counts_list = zip(*word_freq)\n",
    "            ax3.barh(range(len(words_list)), counts_list, color='lightcoral')\n",
    "            ax3.set_yticks(range(len(words_list)))\n",
    "            ax3.set_yticklabels(words_list)\n",
    "            ax3.set_xlabel('Frequency')\n",
    "            ax3.set_title('Most Frequent Words in Challenge Descriptions')\n",
    "            ax3.invert_yaxis()\n",
    "        \n",
    "        # Challenge severity analysis (based on emotional words)\n",
    "        severity_keywords = {\n",
    "            'Hoch': ['extrem', 'sehr', 'enorm', 'massive', 'große', 'schwierig', 'unmöglich'],\n",
    "            'Mittel': ['oft', 'häufig', 'regelmäßig', 'immer wieder', 'ständig'],\n",
    "            'Niedrig': ['manchmal', 'gelegentlich', 'selten', 'wenig']\n",
    "        }\n",
    "        \n",
    "        severity_counts = {level: 0 for level in severity_keywords.keys()}\n",
    "        \n",
    "        for response in all_challenges:\n",
    "            response_lower = response.lower()\n",
    "            for level, keywords in severity_keywords.items():\n",
    "                if any(keyword in response_lower for keyword in keywords):\n",
    "                    severity_counts[level] += 1\n",
    "        \n",
    "        if any(severity_counts.values()):\n",
    "            ax4.bar(severity_counts.keys(), severity_counts.values(), \n",
    "                   color=['red', 'orange', 'yellow'], alpha=0.7)\n",
    "            ax4.set_xlabel('Severity Level')\n",
    "            ax4.set_ylabel('Number of Mentions')\n",
    "            ax4.set_title('Challenge Severity Analysis')\n",
    "            \n",
    "            # Add value labels\n",
    "            for i, (level, count) in enumerate(severity_counts.items()):\n",
    "                if count > 0:\n",
    "                    ax4.text(i, count + 0.1, f'{count}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Generate word cloud for challenges\n",
    "        try:\n",
    "            if all_text:\n",
    "                # Filter text for word cloud\n",
    "                filtered_text = ' '.join([word for word in relevant_words if len(word) > 4])\n",
    "                \n",
    "                if filtered_text:\n",
    "                    plt.figure(figsize=(12, 8))\n",
    "                    wordcloud = WordCloud(width=800, height=400, \n",
    "                                        background_color='white',\n",
    "                                        colormap='Reds',\n",
    "                                        max_words=50).generate(filtered_text)\n",
    "                    \n",
    "                    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "                    plt.axis('off')\n",
    "                    plt.title('Challenge Keywords Word Cloud', fontsize=16, pad=20)\n",
    "                    plt.show()\n",
    "        except ImportError:\n",
    "            print(\"WordCloud library not available. Install with: pip install wordcloud\")\n",
    "        \n",
    "        print(\"Challenge Analysis Summary:\")\n",
    "        print(f\"Total challenge responses analyzed: {len(all_challenges)}\")\n",
    "        print(f\"Number of challenge categories: {len(challenge_cols)}\")\n",
    "        \n",
    "        print(\"\\nTop Challenge Themes:\")\n",
    "        for theme, count in sorted(theme_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            if count > 0:\n",
    "                percentage = (count / len(all_challenges)) * 100\n",
    "                print(f\"- {theme}: {count} mentions ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nMost frequently mentioned challenge words:\")\n",
    "        for word, count in word_freq[:5]:\n",
    "            print(f\"- '{word}': {count} times\")\n",
    "            \n",
    "else:\n",
    "    print(\"No challenge-related columns found for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97cc0804",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:44.560007Z",
     "iopub.status.busy": "2025-10-30T11:45:44.559736Z",
     "iopub.status.idle": "2025-10-30T11:45:44.950554Z",
     "shell.execute_reply": "2025-10-30T11:45:44.949639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Challenge Analysis Summary:\n",
      "Total challenge responses analyzed: 73\n",
      "Number of challenge categories: 3\n",
      "\n",
      "Top Challenge Themes:\n",
      "- Telefon/Unterbrechungen: 13 mentions (17.8%)\n",
      "- Dokumentation: 9 mentions (12.3%)\n",
      "- Terminplanung: 5 mentions (6.8%)\n",
      "- Manuelle Arbeit: 3 mentions (4.1%)\n",
      "- Zeitmanagement: 2 mentions (2.7%)\n",
      "- Technische Probleme: 1 mentions (1.4%)\n",
      "\n",
      "Most frequently mentioned challenge words:\n",
      "- 'versicherungen': 26 times\n",
      "- 'korrespondenz': 26 times\n",
      "- 'krankenkassen': 26 times\n",
      "- 'patienten': 9 times\n",
      "- 'dokumentation': 9 times\n"
     ]
    }
   ],
   "source": [
    "# Pain points and challenges analysis with visualizations\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Try to import wordcloud, but make it optional\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    WORDCLOUD_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WORDCLOUD_AVAILABLE = False\n",
    "    print(\"Note: WordCloud library not available. Word cloud visualization will be skipped.\")\n",
    "\n",
    "# Find challenge-related columns\n",
    "challenge_keywords = ['störfaktoren', 'herausforderungen', 'mühsam', 'zeitaufwendig', 'schwierig', 'problem']\n",
    "challenge_cols = []\n",
    "for col in df.columns:\n",
    "    if any(keyword in col.lower() for keyword in challenge_keywords):\n",
    "        challenge_cols.append(col)\n",
    "\n",
    "if challenge_cols:\n",
    "    # Combine all challenge responses\n",
    "    all_challenges = []\n",
    "    for col in challenge_cols:\n",
    "        responses = df[col].dropna()\n",
    "        all_challenges.extend(responses.tolist())\n",
    "    \n",
    "    if all_challenges:\n",
    "        # Extract key challenge themes\n",
    "        challenge_themes = {\n",
    "            'Telefon/Unterbrechungen': ['telefon', 'anruf', 'unterbrechung', 'störung', 'klingeln'],\n",
    "            'Zeitmanagement': ['zeit', 'zeitaufwendig', 'zeitraubend', 'schnell', 'stress'],\n",
    "            'Manuelle Arbeit': ['manuell', 'hand', 'übertragen', 'kopieren', 'eingeben'],\n",
    "            'Kommunikation': ['kommunikation', 'information', 'weiterleitung', 'abstimmung'],\n",
    "            'Technische Probleme': ['system', 'software', 'technik', 'computer', 'fehler'],\n",
    "            'Dokumentation': ['dokumentation', 'notizen', 'aufschreiben', 'festhalten'],\n",
    "            'Terminplanung': ['termin', 'planung', 'kalender', 'buchung', 'vereinbarung']\n",
    "        }\n",
    "        \n",
    "        theme_counts = {theme: 0 for theme in challenge_themes.keys()}\n",
    "        \n",
    "        for response in all_challenges:\n",
    "            response_lower = response.lower()\n",
    "            for theme, keywords in challenge_themes.items():\n",
    "                if any(keyword in response_lower for keyword in keywords):\n",
    "                    theme_counts[theme] += 1\n",
    "        \n",
    "        # Create comprehensive visualization\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 14))\n",
    "        \n",
    "        # Theme frequency pie chart\n",
    "        valid_themes = {k: v for k, v in theme_counts.items() if v > 0}\n",
    "        if valid_themes:\n",
    "            colors = plt.cm.Set3(range(len(valid_themes)))\n",
    "            wedges, texts, autotexts = ax1.pie(valid_themes.values(), labels=valid_themes.keys(), \n",
    "                                              autopct='%1.1f%%', colors=colors, startangle=45)\n",
    "            ax1.set_title('Main Challenge Themes Distribution')\n",
    "        \n",
    "        # Horizontal bar chart\n",
    "        if valid_themes:\n",
    "            y_pos = range(len(valid_themes))\n",
    "            bars = ax2.barh(y_pos, list(valid_themes.values()), \n",
    "                           color=plt.cm.Set3(range(len(valid_themes))))\n",
    "            ax2.set_yticks(y_pos)\n",
    "            ax2.set_yticklabels(list(valid_themes.keys()))\n",
    "            ax2.set_xlabel('Number of Mentions')\n",
    "            ax2.set_title('Challenge Frequency Analysis')\n",
    "            \n",
    "            # Add value labels\n",
    "            for i, (bar, count) in enumerate(zip(bars, valid_themes.values())):\n",
    "                ax2.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2, \n",
    "                         f'{count}', ha='left', va='center')\n",
    "        \n",
    "        # Word frequency analysis\n",
    "        all_text = ' '.join(all_challenges).lower()\n",
    "        words = re.findall(r'\\b[a-zA-ZäöüÄÖÜß]{4,}\\b', all_text)\n",
    "        \n",
    "        # German stopwords\n",
    "        german_stopwords = {\n",
    "            'sind', 'sich', 'eine', 'einen', 'einer', 'mich', 'für', 'und', 'der', 'die', 'das', \n",
    "            'ich', 'bin', 'haben', 'mit', 'von', 'auf', 'als', 'auch', 'oder', 'aber', 'wenn', \n",
    "            'wird', 'werden', 'wurde', 'kann', 'könnte', 'sollte', 'muss', 'müssen', 'immer', \n",
    "            'sehr', 'noch', 'mehr', 'gibt', 'geht', 'kommt', 'macht', 'sein', 'seine', 'seiner'\n",
    "        }\n",
    "        \n",
    "        relevant_words = [word for word in words if word not in german_stopwords and len(word) > 3]\n",
    "        word_freq = Counter(relevant_words).most_common(15)\n",
    "        \n",
    "        if word_freq:\n",
    "            words_list, counts_list = zip(*word_freq)\n",
    "            ax3.barh(range(len(words_list)), counts_list, color='lightcoral')\n",
    "            ax3.set_yticks(range(len(words_list)))\n",
    "            ax3.set_yticklabels(words_list)\n",
    "            ax3.set_xlabel('Frequency')\n",
    "            ax3.set_title('Most Frequent Words in Challenge Descriptions')\n",
    "            ax3.invert_yaxis()\n",
    "        \n",
    "        # Challenge severity analysis (based on emotional words)\n",
    "        severity_keywords = {\n",
    "            'Hoch': ['extrem', 'sehr', 'enorm', 'massive', 'große', 'schwierig', 'unmöglich'],\n",
    "            'Mittel': ['oft', 'häufig', 'regelmäßig', 'immer wieder', 'ständig'],\n",
    "            'Niedrig': ['manchmal', 'gelegentlich', 'selten', 'wenig']\n",
    "        }\n",
    "        \n",
    "        severity_counts = {level: 0 for level in severity_keywords.keys()}\n",
    "        \n",
    "        for response in all_challenges:\n",
    "            response_lower = response.lower()\n",
    "            for level, keywords in severity_keywords.items():\n",
    "                if any(keyword in response_lower for keyword in keywords):\n",
    "                    severity_counts[level] += 1\n",
    "        \n",
    "        if any(severity_counts.values()):\n",
    "            ax4.bar(severity_counts.keys(), severity_counts.values(), \n",
    "                   color=['red', 'orange', 'yellow'], alpha=0.7)\n",
    "            ax4.set_xlabel('Severity Level')\n",
    "            ax4.set_ylabel('Number of Mentions')\n",
    "            ax4.set_title('Challenge Severity Analysis')\n",
    "            \n",
    "            # Add value labels\n",
    "            for i, (level, count) in enumerate(severity_counts.items()):\n",
    "                if count > 0:\n",
    "                    ax4.text(i, count + 0.1, f'{count}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Generate word cloud for challenges if available\n",
    "        if WORDCLOUD_AVAILABLE and all_text:\n",
    "            # Filter text for word cloud\n",
    "            filtered_text = ' '.join([word for word in relevant_words if len(word) > 4])\n",
    "            \n",
    "            if filtered_text:\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                wordcloud = WordCloud(width=800, height=400, \n",
    "                                    background_color='white',\n",
    "                                    colormap='Reds',\n",
    "                                    max_words=50).generate(filtered_text)\n",
    "                \n",
    "                plt.imshow(wordcloud, interpolation='bilinear')\n",
    "                plt.axis('off')\n",
    "                plt.title('Challenge Keywords Word Cloud', fontsize=16, pad=20)\n",
    "                plt.show()\n",
    "        \n",
    "        print(\"Challenge Analysis Summary:\")\n",
    "        print(f\"Total challenge responses analyzed: {len(all_challenges)}\")\n",
    "        print(f\"Number of challenge categories: {len(challenge_cols)}\")\n",
    "        \n",
    "        print(\"\\nTop Challenge Themes:\")\n",
    "        for theme, count in sorted(theme_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            if count > 0:\n",
    "                percentage = (count / len(all_challenges)) * 100\n",
    "                print(f\"- {theme}: {count} mentions ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nMost frequently mentioned challenge words:\")\n",
    "        for word, count in word_freq[:5]:\n",
    "            print(f\"- '{word}': {count} times\")\n",
    "            \n",
    "else:\n",
    "    print(\"No challenge-related columns found for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e600303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T11:45:44.952626Z",
     "iopub.status.busy": "2025-10-30T11:45:44.952435Z",
     "iopub.status.idle": "2025-10-30T11:45:45.314316Z",
     "shell.execute_reply": "2025-10-30T11:45:45.313314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digital Transformation Analysis Summary:\n",
      "Total digital-related responses: 156\n",
      "Number of digital transformation questions: 6\n",
      "\n",
      "Top Digital Solution Categories:\n",
      "- KI/AI Assistenz: 16 mentions (10.3%)\n",
      "- Online Services: 12 mentions (7.7%)\n",
      "- Automatisierung: 9 mentions (5.8%)\n",
      "- Terminbuchung: 4 mentions (2.6%)\n",
      "- Mobile Lösungen: 3 mentions (1.9%)\n",
      "- Kommunikation: 2 mentions (1.3%)\n",
      "- Datenintegration: 1 mentions (0.6%)\n",
      "- Cloud Services: 1 mentions (0.6%)\n",
      "\n",
      "Digital Readiness Indicators:\n",
      "- Future-focused mentions: 3\n",
      "- Current state mentions: 1\n",
      "→ Strong future orientation - High transformation potential\n"
     ]
    }
   ],
   "source": [
    "# Digital transformation analysis with future-focused visualizations\n",
    "digital_keywords = ['digital', 'online', 'automatisch', 'ki', 'assistent', 'app', 'software']\n",
    "digital_cols = []\n",
    "for col in df.columns:\n",
    "    if any(keyword in col.lower() for keyword in digital_keywords):\n",
    "        digital_cols.append(col)\n",
    "\n",
    "if digital_cols:\n",
    "    # Combine all digital transformation responses\n",
    "    all_digital_responses = []\n",
    "    for col in digital_cols:\n",
    "        responses = df[col].dropna()\n",
    "        all_digital_responses.extend(responses.tolist())\n",
    "    \n",
    "    if all_digital_responses:\n",
    "        # Digital solution categories\n",
    "        digital_categories = {\n",
    "            'Automatisierung': ['automatisch', 'automation', 'auto', 'selbstständig'],\n",
    "            'KI/AI Assistenz': ['ki', 'künstliche intelligenz', 'ai', 'assistent', 'intelligent'],\n",
    "            'Online Services': ['online', 'web', 'internet', 'digital', 'app'],\n",
    "            'Terminbuchung': ['termin', 'buchung', 'appointment', 'calendar', 'kalender'],\n",
    "            'Kommunikation': ['kommunikation', 'chat', 'messenger', 'sms', 'email'],\n",
    "            'Datenintegration': ['integration', 'schnittstelle', 'verbindung', 'sync'],\n",
    "            'Mobile Lösungen': ['mobile', 'smartphone', 'tablet', 'app', 'handy'],\n",
    "            'Cloud Services': ['cloud', 'backup', 'speicher', 'online speicher']\n",
    "        }\n",
    "        \n",
    "        category_counts = {category: 0 for category in digital_categories.keys()}\n",
    "        \n",
    "        for response in all_digital_responses:\n",
    "            response_lower = response.lower()\n",
    "            for category, keywords in digital_categories.items():\n",
    "                if any(keyword in response_lower for keyword in keywords):\n",
    "                    category_counts[category] += 1\n",
    "        \n",
    "        # Create comprehensive digital transformation visualization\n",
    "        fig = plt.figure(figsize=(20, 16))\n",
    "        \n",
    "        # Main digital needs pie chart\n",
    "        ax1 = plt.subplot(3, 3, 1)\n",
    "        valid_categories = {k: v for k, v in category_counts.items() if v > 0}\n",
    "        if valid_categories:\n",
    "            colors = plt.cm.viridis(np.linspace(0, 1, len(valid_categories)))\n",
    "            wedges, texts, autotexts = ax1.pie(valid_categories.values(), labels=valid_categories.keys(), \n",
    "                                              autopct='%1.1f%%', colors=colors, startangle=45)\n",
    "            ax1.set_title('Digital Transformation Needs')\n",
    "        \n",
    "        # Digital readiness radar chart (simulated)\n",
    "        ax2 = plt.subplot(3, 3, 2, projection='polar')\n",
    "        if valid_categories:\n",
    "            categories = list(valid_categories.keys())\n",
    "            values = list(valid_categories.values())\n",
    "            \n",
    "            # Create angles for radar chart\n",
    "            angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "            values += values[:1]  # Complete the circle\n",
    "            angles += angles[:1]\n",
    "            \n",
    "            ax2.plot(angles, values, 'o-', linewidth=2, label='Current Demand')\n",
    "            ax2.fill(angles, values, alpha=0.25)\n",
    "            ax2.set_xticks(angles[:-1])\n",
    "            ax2.set_xticklabels(categories, fontsize=8)\n",
    "            ax2.set_title('Digital Solution Demand Radar')\n",
    "        \n",
    "        # Horizontal bar chart\n",
    "        ax3 = plt.subplot(3, 3, 3)\n",
    "        if valid_categories:\n",
    "            y_pos = range(len(valid_categories))\n",
    "            bars = ax3.barh(y_pos, list(valid_categories.values()), \n",
    "                           color=plt.cm.viridis(np.linspace(0, 1, len(valid_categories))))\n",
    "            ax3.set_yticks(y_pos)\n",
    "            ax3.set_yticklabels(list(valid_categories.keys()), fontsize=8)\n",
    "            ax3.set_xlabel('Mentions')\n",
    "            ax3.set_title('Digital Solution Priorities')\n",
    "        \n",
    "        # Future vs Current state analysis\n",
    "        ax4 = plt.subplot(3, 3, 4)\n",
    "        future_keywords = ['wunsch', 'wünschen', 'träumen', 'perfekt', 'ideal', 'zukunft']\n",
    "        current_keywords = ['aktuell', 'derzeit', 'momentan', 'jetzt', 'heute']\n",
    "        \n",
    "        future_mentions = sum(1 for response in all_digital_responses \n",
    "                             if any(keyword in response.lower() for keyword in future_keywords))\n",
    "        current_mentions = sum(1 for response in all_digital_responses \n",
    "                              if any(keyword in response.lower() for keyword in current_keywords))\n",
    "        \n",
    "        ax4.bar(['Current State', 'Future Wishes'], [current_mentions, future_mentions], \n",
    "               color=['lightblue', 'darkblue'], alpha=0.7)\n",
    "        ax4.set_ylabel('Number of Mentions')\n",
    "        ax4.set_title('Current vs Future Digital Needs')\n",
    "        \n",
    "        # Innovation potential matrix\n",
    "        ax5 = plt.subplot(3, 3, 5)\n",
    "        # Simulate innovation potential vs implementation difficulty\n",
    "        innovation_data = []\n",
    "        for category, count in valid_categories.items():\n",
    "            # Simulate difficulty (higher for complex solutions)\n",
    "            difficulty_map = {\n",
    "                'KI/AI Assistenz': 8, 'Datenintegration': 7, 'Cloud Services': 6,\n",
    "                'Mobile Lösungen': 5, 'Online Services': 4, 'Automatisierung': 6,\n",
    "                'Kommunikation': 3, 'Terminbuchung': 4\n",
    "            }\n",
    "            difficulty = difficulty_map.get(category, 5)\n",
    "            innovation_data.append((count, difficulty, category))\n",
    "        \n",
    "        if innovation_data:\n",
    "            x_vals, y_vals, labels = zip(*innovation_data)\n",
    "            scatter = ax5.scatter(x_vals, y_vals, s=[x*50 for x in x_vals], \n",
    "                                 c=range(len(x_vals)), cmap='plasma', alpha=0.7)\n",
    "            \n",
    "            for i, label in enumerate(labels):\n",
    "                ax5.annotate(label, (x_vals[i], y_vals[i]), fontsize=8, ha='center')\n",
    "            \n",
    "            ax5.set_xlabel('Demand Level')\n",
    "            ax5.set_ylabel('Implementation Complexity')\n",
    "            ax5.set_title('Innovation Opportunity Matrix')\n",
    "        \n",
    "        # Digital maturity timeline\n",
    "        ax6 = plt.subplot(3, 1, 3)\n",
    "        # Simulate adoption timeline based on responses\n",
    "        adoption_phases = {\n",
    "            'Basic Digitization': ['email', 'computer', 'software'],\n",
    "            'Process Automation': ['automatisch', 'system', 'integration'],\n",
    "            'AI Integration': ['ki', 'intelligent', 'assistent'],\n",
    "            'Full Digital Transformation': ['digital', 'transformation', 'komplett']\n",
    "        }\n",
    "        \n",
    "        phase_scores = {}\n",
    "        for phase, keywords in adoption_phases.items():\n",
    "            score = sum(1 for response in all_digital_responses \n",
    "                       if any(keyword in response.lower() for keyword in keywords))\n",
    "            phase_scores[phase] = score\n",
    "        \n",
    "        phases = list(phase_scores.keys())\n",
    "        scores = list(phase_scores.values())\n",
    "        \n",
    "        bars = ax6.bar(range(len(phases)), scores, \n",
    "                      color=['lightgreen', 'yellow', 'orange', 'red'], alpha=0.7)\n",
    "        ax6.set_xticks(range(len(phases)))\n",
    "        ax6.set_xticklabels(phases, rotation=45, ha='right')\n",
    "        ax6.set_ylabel('Mentions')\n",
    "        ax6.set_title('Digital Maturity Spectrum')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, score in zip(bars, scores):\n",
    "            if score > 0:\n",
    "                ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "                         f'{score}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Digital Transformation Analysis Summary:\")\n",
    "        print(f\"Total digital-related responses: {len(all_digital_responses)}\")\n",
    "        print(f\"Number of digital transformation questions: {len(digital_cols)}\")\n",
    "        \n",
    "        print(\"\\nTop Digital Solution Categories:\")\n",
    "        for category, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            if count > 0:\n",
    "                percentage = (count / len(all_digital_responses)) * 100\n",
    "                print(f\"- {category}: {count} mentions ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nDigital Readiness Indicators:\")\n",
    "        print(f\"- Future-focused mentions: {future_mentions}\")\n",
    "        print(f\"- Current state mentions: {current_mentions}\")\n",
    "        \n",
    "        if future_mentions > current_mentions:\n",
    "            print(\"→ Strong future orientation - High transformation potential\")\n",
    "        else:\n",
    "            print(\"→ Current focus - Immediate solution needs\")\n",
    "            \n",
    "else:\n",
    "    print(\"No digital transformation columns found for analysis\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
